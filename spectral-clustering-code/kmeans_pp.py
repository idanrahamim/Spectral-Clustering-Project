"""This module implements k-means++ algorithm using mykmeanssp helping module written in C"""
import numpy as np
import mykmeanssp


def generate_init_centroids(observations, k):
    """
    Takes as a parameter the observation array as a numpy array of dimensions (n,d)
    returns indices of observations chosen as initial clusters

    :param observations (numpy.ndarray) observation array as a numpy array of dimensions (n,d)
    :param k (int) number of clusters
    :return indices of the observations chosen as initial clusters
    """
    np.random.seed(0)
    n = observations.shape[0]
    indices = np.arange(n)
    centroids = [np.random.choice(indices)]
    # List of minimal distances to each point
    min_dist_list = [np.square(obs - observations[centroids[0]]).sum() for obs in observations]
    # Choose each centroid randomly
    for j in range(1, k):
        prob = calculate_probability(observations, centroids, min_dist_list)
        centroids.append(np.random.choice(indices, p=prob))
    return np.array(centroids)


def calculate_probability(observations, centroids, min_dist_list):
    """
    Calculates probabilities for each point in observations array to be chosen. Uses algorithm described in the
    2-nd homework

    :param observations (numpy.ndarray) array of d-dimensional points (observations)
    :param centroids (list) python list of initial centroids
    :param min_dist_list (list) python list of minimal distances to each point (the list will be changed inside this
    function)
    :return python list of probabilities for each point in observations
    """
    distances = []
    # Calculate initial distances
    for i, obs in enumerate(observations):
        new_dist = np.square(obs - observations[centroids[-1]]).sum()
        min_dist_list[i] = min(min_dist_list[i], new_dist)
        distances.append(min_dist_list[i])

    distances = np.array(distances)
    dist_sum = np.sum(distances)
    # If dist_sum is 0 (behaviour in this case was defined on forum)
    if dist_sum == 0:
        return [1 / len(observations)] * len(observations)
    return distances / dist_sum


def kmeans_pp(k, n, d, max_iter, observations):
    """
    Applies K-means++ algorithm to a given array of points and returns clusters generated by the algorithm

    :param k (int) number of clusters to generate
    :param n (int) number of points
    :param d (int) dimension of each point
    :param max_iter (int) max number of iterations to use
    :param observations (numpy.ndarray) array of d-dimensional points (observations)
    :return numpy.ndarray of size n with indices of clusters for each point
    """
    # Compute initial centroids
    init_centroids_indices = generate_init_centroids(observations, k)
    init_centroids = observations[init_centroids_indices]
    # Apply K-means algorithm
    final_centroids = np.array(
        mykmeanssp.compute_centroids(k, n, d, max_iter, observations.tolist(), init_centroids.tolist()),
        dtype=np.float64)
    return np.array([np.square(p - final_centroids).sum(axis=1).argmin() for p in observations])
